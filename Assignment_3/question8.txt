Imputations as discussed in class could be used to replace low quality calls, reducing the error rate. 
The process would be to extract high-quality SNPs from the aligned reads and use them to find the most likely calls for misaligned areas of the aligned reads.
This would require access to a large database of already-sequenced human genomes that could provide the most likely context for the high-quality SNPs.
Backtracking to find the 'better' calls via imputation might improve MinION base-calling overall if more profiling of the errors could be done.
Even lower quality SNPs, if imputation yields a result mostly agreeing with the SNP's context, could be used for imputation.

Ignoring alignments to error-prone regions would also reduce error rate. These may be specific to Oxford Nanopore technology.
If enough reads from different samples using MinIONs were aligned, a distribution of errors across the human genome could be found.
This distribution would be expected to be uniform, but there will likely by systematic errors that skew the data in certain regions, perhaps regions with high GC count, given what we already know about MinION.
Ignoring alignments to these regions would reduce the error rate in addition to the overall number of errors, although there would also be some data loss as a result.

Since the beginnings and ends of reads are known to be more error-prone than the middle, a certain number of bases from the beginning and ends of reads could be trimmed before alignment.
This may allow more reads to be successfully aligned, and may decrease the error rate.
There would be a lot of data loss, but imputation could mitigate that problem.
Metrichor's base-calling likely already takes this into account, but that may only make the 'edge' areas of reads more prone to systematic error issues.